In this section we present the essential theoretical background and context for this thesis. First introducing fundamental concepts in software engineering, the software development lifecycle (SDLC), continuous integration (CI), and the software project hosting platforms. The second part explores the rising role of GenAi/LLMs in software development practices.The third part showcases the evolution and state of APR and explores existing approaches.

\section{Software Engineering}
The following section introduces core concepts starting with the software development lifecycle,the importance of Continuous Integration (CI) in modern software development and the role of code hosting platforms.
\subsection{Software Development Lifecycle}
Engineering and developing software is complex process, consisting of multiple different tasks. For structuring this process software development lifecycle models have been introduced. These models evolve constantly to adapt to the changing needs of creating software. The most promising and widely used model today is the Agile Software Development Lifecycle \cite{rupareliaSoftwareDevelopmentLifecycle2010}.

The Agile lifecycle brings an iterative approach to development, focusing on collaboration, feedback and adaptivity. The Goal is frequent delivery of small functional features of software, allowing for continuous improvement and adaptation to changing requirements. Using frameworks like Scrum or Kanban, an Agile iteration can be applied in a development environment\cite{rupareliaSoftwareDevelopmentLifecycle2010}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/agile-cycle.png}
    \caption{Agile Software Development Lifecycle}
    \label{fig:agile-cycle}
\end{figure}

An Agile Software Development Lifecycle iteration consists of 6 key stages like in Figure \ref{fig:agile-cycle} starting with planning phase where requirements for the iteration are gathered and prioritized. Secondly the design phase where the architecture and design of the feature is created. The third stage is where the actual development of the prioritized requirements takes place. After that the testing phase follows, where the software is tested for bugs and issues. The fifth stage is deployment, where the software is released to users. Finally, the changes are reviewed in a collaborative way.

When bugs arise during an iteration requirements can be reprioritized and the iteration can be adapted to fix these issues. This adaptivity is a key feature of Agile software development, allowing teams to respond quickly to changing requirements and issues but also slowing down delivery of planed features \cite{rupareliaSoftwareDevelopmentLifecycle2010}.

Modern software systems are moving towards lightly coupled microservice architectures, which results in more repositories which are smaller in scale tailored towards a specialized domain. This trend is driven by the need for flexibility, scalability, and faster development cycles. Smaller code repositories allow teams to work on specific components or services independently, reducing dependencies and enabling quicker iterations. This approach aligns with modern software development practices, such as microservices architecture and agile methodologies.
With this trend developers work on multiple projects at the same time, which can lead to more interruptions and context switching when problems arise and priorities shift.


\subsection{Continuous Integration}
For accelerating the delivery of software in an iteration continuous integration has become a standard in agile software development. The main objective of continuous integration is to accelerate phases 3 and 4 \cite{ugwuezeContinuousIntegrationDeployment2024}. CI allows for frequent code integration into a code repository. Automating steps like building and testing into the development resulting in rapid feedback right where the changes are committed in a shared repository. This supports critical aspects of agile software development, like fast delivery, fast feedback and enhanced collaboration \cite{ugwuezeContinuousIntegrationDeployment2024}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/ci-cycle.png}
    \caption{Continuous Integration Cycle}
    \label{fig:ci-cycle}
\end{figure}

Although CI bring a lot of potential to agile development it can also has drawbacks. Long build durations and high maintenance. %\cite{}

\subsection{Software Project Hosting Platforms} \label{subsection:Software Project Hosting Platforms}
Software projects live on platforms like Github or GitLab. With GitHub being the most popular and most used for open source %\cite{} 
These platforms offer tools and services for the entire software development lifecycle, including project hosting, version control, issue tracking, bug reporting, project management, backups, collaborative workflows, and documentation capabilities. \cite{abrahamssonAgileSoftwareDevelopment2017}

Github issues are a key feature of Github allowing for project scoped tracking of features, bugs, and tasks. Issues can be created, assigned, labeled, and commented on by everyone working on a codebase. This feature provides a structured way to manage and prioritize work within a project.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/github/GitHub Issue.png}
    \caption{Example of a GitHub Issue}
    \label{fig:gh-issue}
\end{figure}

For integrating and reviewing code into production GitHub provides Pull Requests. A Pull Request proposes changes to the codebase, providing an integrated review process to validate changes before they are integrated into the production codebase. Code changes are displayed in a diff format \footnote{TODO explain format} allowing reviewers to see and dig into the changes made.This process is essential for maintaining code quality and ensuring that changes are validated before being merged. %\cite{githubdoc}
Pull requests can be linked to Issues, allowing for easy tracking of changes related to specific tasks or bugs. %\cite{githubdoc}

GitHub also provides a manged solution (Github Actions) for integrating CI into a repositories by writing CI workflows in YAML files. Workflows can run as CI pipelines on runners hosted by GitHub or self hosted runners. A workflow consists of triggers and jobs, and steps. One or more events can trigger a workflow which executed one ore more jobs which are made up of one or more steps. \cite{Workflows} An example is shown in Figure \ref{fig:gh-workflow}. Workflow results and logs can be viewed from multiple points in the GitHub web UI , including the Actions tab, the Pull Request page, and the repository's main page. This integration provides a seamless experience for developers to monitor and manage their CI processes directly within their repositories.

\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{images/overview-actions-simple.png}
    \caption{Simple Action}
    \label{fig:gh-workflow}
\end{figure}
\FloatBarrier

\section{Generative AI in Software Development}
This section will cover the role of Generative AI in software development. First we will define Generative AI and Large Language Models (LLMs). The second part will focus on the impact of Generative AI on software development practices.
\subsection{Generative AI and Large Language Models}
Generative Artificial Intelligence (Gen AI) is subfield of artificial intelligence and refers to systems that can generate new content based on patterns learned from massive amounts of training data. Advanced machine learning techniques, particularly deep learning, enable these systems to generate text, images, or code, that resembles human-generated output.
In the field of natural language processing (NLP) was revolutionized by the Transformer architecture \cite{changSurveyEvaluationLarge2024}. It lays the ground work for Large Language Models which are specialized in text generation. Extensive training data results in Models billions of parameters, allows them to understand and generate human-like text in multiple natural languages and diverse programming languages. However this requires enormous computational resources during training and operation \cite{LLMsWhatsLarge}. A models parameter count has a direct impact on the model's performance, with larger models generally achieving better results in various NLP tasks but also demanding more computational resources %\cite{}. 
Despite modern LLMs showing promising results, they can still hallucinate incorrect or biased content. \cite{LLMsWhatsLarge}.

To archive a specific task using LLMs designing and providing specific input to the model to guide its output is called prompt engineering. This process is crucial for achieving desired results from LLMs, as the quality and specificity of the prompt directly influences the model's output. The input is constrained by a models context window, which is the maximum amount of text the model can process at once.

Popular Large Language Models are offered via APIs but providers like OpenAi, Anthropic and Google, or open source alternatives like X. Table \ref{table:llms} shows a selection of popular LLMs with their characteristics and performance on NLP benchmark X which evaluates X.
\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} p{3cm} | p{2cm} | p{2cm} | p{4cm} @{}}
        \toprule
        \textbf{Model Name} & \textbf{Publisher} & \textbf{Parameters} & \textbf{Context Windows Size} \\
        \midrule
        chatgpt & OpenAI & 175B & 1M \\ \hline
        \bottomrule
    \end{tabular*}
    \caption{Large Language Model Examples}
    \label{table:llms}
\end{table}


\subsection{Large Language Models in Software Development}
Large Language Models are reshaping software development by automating various tasks. They have billions of parameters and are pre-trained on massive codebases which results in extraordinary capabilities in this area \cite{chenUnveilingPitfallsUnderstanding2025}. Tools like Github Copilot, OpenAI Codex, and ChatGPT have become popular in the software development community, providing developers with AI-powered code suggestions and completions \cite{bhargavmallampatiRoleGenerativeAI2025}. These tools get applied in various stages of the software development lifecycle, including requirement engineering, code generation, debugging, refactoring, and testing \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025,bhargavmallampatiRoleGenerativeAI2025}. By using LLMs to enhance the named tasks development cycle times can be reduced by up to 30 percent \cite{bhargavmallampatiRoleGenerativeAI2025,kalliamvakouResearchQuantifyingGitHub2022}. Furthermore these tools have positive impacts like improving developer satisfaction and reducing cognitive load \cite{kalliamvakouResearchQuantifyingGitHub2022}.

Although Generative AI gets adopted really quickly in many areas of software development this technology still faces limitations. LLMs have challenges working on tasks that are outside their scope of training or require specific domain knowledge \cite{houLargeLanguageModels2024}. Additionally LLMs have limited context windows, which can lead to challenges when working with large codebases or complex projects where context windows are too small for true contextual or requirements understanding \cite{bhargavmallampatiRoleGenerativeAI2025}. When generating code LLMs can produce incorrect or insecure code, which can lead to further bugs and vulnerabilities in the software \cite{houLargeLanguageModels2024, bhargavmallampatiRoleGenerativeAI2025}. Additionally when integrating LLMs into tools can be vulnerable to prompt injection, where unintended instructions are injected at some point and can also lead to production of harmful code \cite{liuPromptInjectionAttack2024}. Code generated by LLMs based on training data also raises questions about ownership, responsibility and intellectual property rights. \cite{sauvolaFutureSoftwareDevelopment2024, houLargeLanguageModels2024}.

Facing these challenges, different approaches have been developed. AI Agents, RAG or interactive approaches are prominent examples. These approaches aim to enhance the capabilities of LLMs by providing additional context, enabling multi-step reasoning, or allowing for interactive feedback loops during code generation and debugging \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025}. Section \ref{subsection:evolution-apr} will go into more detail on these approaches.

Recently research is exploring solutions which integration LLMs into existing software development practices and workflows. \cite{puvvadiCodingAgentsComprehensive2025, dohmkeGitHubCopilotMeet2025, IntroducingCodex, sauvolaFutureSoftwareDevelopment2024}. This happens in tools and on platform where development happens and focuses on for example integrating AI/ML into CI/CD \cite{mohammedAIDrivenContinuousIntegration2024} or into code hosting platforms like GitHub \ref{subsection:Software Project Hosting Platforms}.

\section{Automated Program Repair}

Automated Program Repair (APR) is done by software that helps to detect and repair bugs in code with minimal human intervention.  This field has also benefited of the rapid advancements in AI.

APR system are supposed to take over the process of fixing bugs therefore making more time for developers to focus on more relevant work. \cite{houLargeLanguageModels2024}

Specific bugs can be fixed using a resulting patch from an APR system. For creating working patches APR takes a 3 stage approach: First localizing the bug. Then repairing the bug, in the end validation decides where the bug will be passed on.\cite{}

In this section we will provide an overview of the evolution of APR, related work, and the current state of APR systems.

\subsection{Evolution of Automated Program Repair} \label{subsection:evolution-apr}
We have seen multiple transformations in the field of Automated Program Repair (APR) over the years. This evolution of APR can be categorized into key stages, each marked by significant advancements in techniques and methodologies.

\textbf{Traditional Approaches:}\\
Prior APR approaches were based on version control history, using the history to roll back to a previous version of the code part, where no issues were present. This approach, while effective in some cases, often lacked the ability to preserve new features. (more like instant rollback)

Template based systems relied on predefined template for transformations of commonly known bugs. Templates applied predefined transformations to the code based on fixed rules. This approach had limited the flexibility and adaptability in a quickly transforming software landscape. \cite{puvvadiCodingAgentsComprehensive2025}

%TODO
Search based repair,

%TODO
Semantic based repair,

One of the most outstanding system is Getafix develop and deployed at Meta \cite{baderGetafixLearningFix2019}

Nevertheless traditional systems face significant limitations in scalability and adaptability, struggling to generalize to new scenarios or unseen bugs, or to adapt to evolving codebases. They often required extensive computational resources or manual effort. \cite{puvvadiCodingAgentsComprehensive2025}


\textbf{The emerge of llm based APR:}
LLM based APR techniques have demonstrated significant improvements over all other state of the art techniques, benefitting from the coding knowledge \cite{hossainDeepDiveLarge2024}For that reason LLMs lay the groundwork of a new APR paradigm \cite{chenUnveilingPitfallsUnderstanding2025}.
Common LLMS used for APR include GPT-4, ChatGPT, Codex, CodeLlama, DeepSeek-Coder, and CodeT5 \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024,anandComprehensiveSurveyAIDriven2024}.

Using LLMs diffrent Paradigms have emerged and are being actively researched. These paradigms include:

Retrieval-Augmented Approaches repair bugs with the help of retrieving relevant context during the repair process. This approach allows adding external knowledge to the repair process, enhancing the LLM's ability to understand and fix bugs \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024}.

Agent based system improve fixing abilites by probiding llms the ability to interact with the code base and the environment, allowing them to plan their actions. These frameworks recosncturct the cognitve processes using multiple Agents that can generate code with the help of multi-step reasoning, usage of tools for  with Envrioments and Tools %\cite{}.
Examples for that are SWE-Agent \cite{yangSWEagentAgentComputerInterfaces2024}, FixAgent \cite{leeUnifiedDebuggingApproach2024}, MarsCodeAgent \cite{liuMarsCodeAgentAInative2024}, GitHub Copilot.

complex agent architectures produce good results epically paired with containerized environments. \cite{puvvadiCodingAgentsComprehensive2025}

Interactive approaches make use of LLMs dialogue capabilities to equip patch validation with instant feedback. This feedback is used to refine the generated patches trying to archive better results. This process takes a more dynamic and iterative approach. \cite{xiaAutomatedProgramRepair2024}

Agentless systems are recent a push towards more lightweight solution, focusing on simplicity and efficiency. These approaches aim to reduce the complexity of APR systems while maintaining effectiveness in bug fixing \cite{xiaAgentlessDemystifyingLLMbased2024}. Furthermore this approach provides clear rails to the LLMS improving the transparency of the bug fixing approach taken.
These Systems have achieved promising results  with low costs \cite{xiaAgentlessDemystifyingLLMbased2024}

% TODO mention codex and copilot??

Common problems currently faced by state of the art APR system are:
Exsiting system are overly complex with limited transparency and control over the bug fixing process.\cite{xiaAgentlessDemystifyingLLMbased2024,puvvadiCodingAgentsComprehensive202, houLargeLanguageModels2024}
Repairing bugs takes a lot of computational resources and is time intensive therefore producing significant costs  \cite{sobaniaAnalysisAutomaticBug2023,puvvadiCodingAgentsComprehensive2025}
Repairing bugs is done on benchmarks or in controlled set up environments and not integrated into real world software development workflows \cite{meemExploringExperiencesAutomated2024,puvvadiCodingAgentsComprehensive2025}

\subsection{APR benchmarks}
For standardizing evaluation in research of new APR approaches benchmarks have been developed. These benchmarks consist of a set of software bugs and issues, along with their corresponding fixes, which can be used to evaluate the effectiveness of different APR techniques. They are essential for comparing the performance of different APR systems and understanding their strengths and weaknesses.
Widely used benchmarks are QuixBugs, Defects4J and SWE Bench. %\cite{}
---
Table
\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} p{2cm} | p{2cm} | p{2cm} | p{5cm} | p{4cm} @{}}
        \toprule
        \textbf{Model} & \textbf{Languages} & \textbf{Num of Bugs} & \textbf{Description} & \textbf{Difficulty} \\
        \midrule
        Quixbugs & Python, Java & 40 & small single line bugs in Python code  & Easy \\ \hline
        Defects4J & Java & 854 & real-world Java bugs & Medium \\ \hline
        SWE Bench & Python, JavaScript & 2294 & Real GitHub defects in software engineering repositories & Hard \\ \hline
        \bottomrule
    \end{tabular*}
    \caption{Functional requirements (F0--F8)}
\end{table}

---TABLE of benchmarks, num of issues, languages, size, complexity, etc.