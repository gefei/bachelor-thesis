Generative AI is rapidly changing the software industry and how software is developed and maintained. The emergence of Large Language Models (LLMs), a subfield of Generative AI, has opened up new opportunities for enhancing and automating various domains of the software development lifecycle. Due to remarkable capabilities in understanding and generating code snippets, LLMs have become valuable tools for developers' everyday tasks such as requirement engineering, code generation, refactoring, and program repair \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025}.

Despite these advances, bug fixing remains a challenging and resource intensive task, often negatively perceived by developers  \cite{winterHowDevelopersReally2023}. It can cause frequent interruptions and context switching resulting in reduced developer productivity  \cite{vasilescuSkyNotLimit2016}.
Software bugs have direct impact on software quality by causing crashes, vulnerabilities or even data loss \cite{tihanyiNewEraSoftware2024}.
The process of bug fixing can be time-consuming, leading to delays in software delivery and increased costs. %\cite{}
In fact, according to CISQ, poor software quality cost the U.S. economy over \$2.4 trillion in 2022, with \$607 billion spent solely on finding and paring bugs \cite{CostPoorSoftware}.

Given the critical role of debugging and bug fixing in software development, Automated Program Repair (APR) has gained significant research interest. The goal of APR is to automate the complex process of bug fixing \cite{houLargeLanguageModels2024} which typically involves localization, repair, and validation \cite{zhangEmpiricalStudyFactors2012, leeUnifiedDebuggingApproach2024,xiaAgentlessDemystifyingLLMbased2024,zhangPATCHEmpoweringLarge2025, wangEmpiricalResearchUtilizing2025}.
Recent research has shown that LLMs can effectively be used to enhance automated bug fixing, thereby introducing new standards in the APR world showing potential of making significant improvements in efficiency of the software development process \cite{xiaAgentlessDemystifyingLLMbased2024,liuMarsCodeAgentAInative2024,yangSWEagentAgentComputerInterfaces2024, sobaniaAnalysisAutomaticBug2023, xiaAutomatedProgramRepair2024, huCanGPTO1Kill2024}.

However, existing APR approaches are often complex and require significant computational resources \cite{rondonEvaluatingAgentbasedProgram2025}, making them less suitable for budget-constrained environments or individual developers. Additionally, the lack of integration with existing software development lifecycles and workflows limits their practical applicability in real-world development environments \cite{chenUnveilingPitfallsUnderstanding2025,liuMarsCodeAgentAInative2024}.

Motivated by these challenges, this thesis explores the potential of integrating LLM based automated bug fixing into existing software development workflows. Modern software development  makes use of continuous integration to ensure rapid, reliable releases. \cite{ugwuezeContinuousIntegrationDeployment2024} By leveraging the capabilities of LLMs, we aim to develop a cost-effective prototype for automated bug fixing that seamlessly integrates using continuous integration (CI) pipelines. Considering computational demands, complexity of integration and practical constraints we aim to provide insights into possibilities and limitations of our approach answering the following research questions:

\begin{itemize}
    \item \textbf{RQ1:} How can LLM-based automated bug fixing be effectively and efficiently integrated into a CI pipeline?
    \item \textbf{RQ2:} What are the key potentials of this integrated approach in terms of repair success rate, cost-effectiveness and developer workflow enhancement?
    \item \textbf{RQ3:} What are the primary limitations and challenges, such as performance overhead, accuracy, and security, of using LLM-based APR within a CI context?
\end{itemize}


The thesis is organized as follows:

Section 2 provides theoretical background on the Software Development, Generative AI in context of software development and Automated Program Repair.\\
Section 4 and 5 go into the process of developing the prototype based on the requirements and methodology.\\
Section 6 showcases the resulting workflow and evaluation results for the Quixbugs benchmark.\\
Section 7 discusses the results and limitations of the prototype giving insights into lessons learned and a future outlook.\\
Finally section 8 concludes the thesis by summarizing the findings and contributions of this work.